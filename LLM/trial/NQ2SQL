import torch
# from transformers import MistralTokenizer, MistralForConditionalGeneration
import snowflake.connector

# Step 1: Connect to Snowflake
conn = snowflake.connector.connect(

)


from huggingface_hub import login

# Use your token to log in


from transformers import LlamaForCausalLM, LlamaTokenizer

# Load the model and tokenizer with your token
model_name = 'meta-llama/Llama-2-7b'
model = LlamaForCausalLM.from_pretrained(model_name, use_auth_token=True)
tokenizer = LlamaTokenizer.from_pretrained(model_name, use_auth_token=True)

def convert_to_sql(user_query):
    # Prepare the input prompt for the model
    input_text = f"Translate the following user query into an SQL query for the table insurance_table: {user_query}"
    inputs = tokenizer.encode(input_text, return_tensors='pt', max_length=512, truncation=True)

    # Generate the output (SQL query)
    outputs = model.generate(inputs, max_length=150, num_beams=4, early_stopping=True)
    sql_query = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return sql_query


user_query = "What is the cost for customer ID 10000005 on their 5th shopping point?"
sql_query = convert_to_sql(user_query)
print(sql_query)

# # Execute the SQL query
# cursor = conn.cursor()
# cursor.execute(sql_query)
# results = cursor.fetchall()

# # Print the results
# for row in results:
#     print(row)