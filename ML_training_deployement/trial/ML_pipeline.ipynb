{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKZIwD2QH50G",
        "outputId": "a68ed586-69b7-4eeb-b434-9bdc5040106c"
      },
      "outputs": [],
      "source": [
        "# !pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSrAxKeb9AxK",
        "outputId": "e48c6336-798d-4473-bb12-61f23dfd30fa"
      },
      "outputs": [],
      "source": [
        "!pip install snowflake-connector-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYW2PiYmFU_R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import snowflake.connector\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.stats import mode\n",
        "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ld81vVdcabQX"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3O5FsPS-aYqE",
        "outputId": "1246b158-3cee-4124-fadd-f4107890db7b"
      },
      "outputs": [],
      "source": [
        "!python --version\n",
        "# .__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whIVGoWD5GxK"
      },
      "source": [
        "###Imputation+ Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CU5r2ZmU9Nov"
      },
      "outputs": [],
      "source": [
        "# Step 1: Connect to Snowflake\n",
        "conn = snowflake.connector.connect(\n",
        "    user='CHINMAYA54',\n",
        "    password='Chiy@#542',\n",
        "    account='sgb52108.us-east-1',\n",
        "    warehouse='INSURANCEWH',\n",
        "    database='INSURANCEDB',\n",
        "    schema='INSURANCESCHEMA',\n",
        "    role='ACCOUNTADMIN',\n",
        ")\n",
        "\n",
        "# Step 2: Execute SQL Query\n",
        "cur = conn.cursor()\n",
        "cur.execute('SELECT * FROM insurancetable')\n",
        "\n",
        "# Step 3: Fetch Data\n",
        "data = cur.fetchall()\n",
        "df = pd.DataFrame(data, columns=[x[0] for x in cur.description])\n",
        "\n",
        "# print(df)\n",
        "\n",
        "# Step 4: Close the Connection\n",
        "cur.close()\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "NDKQFDWM9eb9",
        "outputId": "3d155138-30c3-4af6-e991-1e6a9c9e8b0c"
      },
      "outputs": [],
      "source": [
        "# Display the first few rows of the dataset\n",
        "print(\"\\nFirst 5 rows of the dataset:\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IqK1mED9ZEh",
        "outputId": "ab434d51-9bc5-47f2-a0ec-3a245bcdcdb0"
      },
      "outputs": [],
      "source": [
        "# Display basic information about the dataset\n",
        "print(\"Dataset Information:\")\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "B_3qT69f9i_5",
        "outputId": "d5bb15f7-ecd9-47d6-bcb9-869724d2bc0d"
      },
      "outputs": [],
      "source": [
        "# Summary statistics for numerical columns\n",
        "print(\"\\nSummary statistics for numerical columns:\")\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl6iL7dt_b-g",
        "outputId": "5c332673-0a72-43a1-c304-2f9ea1651faa"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ng0FDqpx9m4j",
        "outputId": "3dfdf657-edac-4725-9415-17ea1075dce7"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(\"\\nMissing values:\")\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MecHRfx0-ZCL"
      },
      "outputs": [],
      "source": [
        "# df['DURATION_PREVIOUS'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hq-NVyWdFOnz"
      },
      "outputs": [],
      "source": [
        "# Replace empty strings with NaN\n",
        "df['STATE'].replace('', np.nan, inplace=True)\n",
        "df['CAR_VALUE'].replace('', np.nan, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BptQnJ9DF0t",
        "outputId": "58b37748-ede9-4f85-8642-af70634790c8"
      },
      "outputs": [],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mo6SSc8EDAL1"
      },
      "outputs": [],
      "source": [
        "df.drop_duplicates(inplace =True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoKMwP2BF4XL",
        "outputId": "ae9affc4-aafe-42f4-8a9f-afe028d1906f"
      },
      "outputs": [],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "kft30vfbC35z",
        "outputId": "979ba93c-2e04-42a1-9512-d613310bcf1e"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0iUQXuQDbGL"
      },
      "outputs": [],
      "source": [
        "# Impute missing values\n",
        "def impute_grouped_data(df, column, method='mode'):\n",
        "    if method == 'mode':\n",
        "        df[column] = df.groupby('CUSTOMER_ID')[column].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else x))\n",
        "    elif method == 'median':\n",
        "        df[column] = df.groupby('CUSTOMER_ID')[column].transform(lambda x: x.fillna(x.median()))\n",
        "    elif method == 'mean':\n",
        "        df[column] = df.groupby('CUSTOMER_ID')[column].transform(lambda x: x.fillna(x.mean()))\n",
        "    elif method == 'ffill':\n",
        "        df[column] = df.groupby('CUSTOMER_ID')[column].transform(lambda x: x.fillna(method='ffill'))\n",
        "    elif method == 'bfill':\n",
        "        df[column] = df.groupby('CUSTOMER_ID')[column].transform(lambda x: x.fillna(method='bfill'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNdIvyx0D6Ky"
      },
      "outputs": [],
      "source": [
        "# Columns to impute and their methods\n",
        "columns_to_impute = {\n",
        "    'LOCATION': 'mode',\n",
        "    'GROUP_SIZE': 'mode',\n",
        "    'HOMEOWNER': 'mode',\n",
        "    'STATE': 'mode',\n",
        "    'CAR_VALUE': 'mode',\n",
        "    'CAR_AGE': 'mode',\n",
        "    'RISK_FACTOR': 'mode',\n",
        "    'AGE_OLDEST': 'mode',\n",
        "    'AGE_YOUNGEST': 'mode',\n",
        "    'MARRIED_COUPLE': 'mode',\n",
        "    'C_PREVIOUS': 'mode',\n",
        "    'DURATION_PREVIOUS': 'mode',\n",
        "    'A': 'mode',\n",
        "    'B': 'mode',\n",
        "    'C': 'mode',\n",
        "    'D': 'mode',\n",
        "    'E': 'mode',\n",
        "    'F': 'mode',\n",
        "    'G': 'mode'\n",
        "}\n",
        "\n",
        "# Apply imputation\n",
        "for column, method in columns_to_impute.items():\n",
        "    impute_grouped_data(df, column, method)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rU_ZmZ__cMoQ"
      },
      "outputs": [],
      "source": [
        "# Drop rows where SHOPPING_PT is null\n",
        "df = df.dropna(subset=['SHOPPING_PT'])\n",
        "\n",
        "# Sort the rows based on CUSTOMER_ID and SHOPPING_PT\n",
        "df = df.sort_values(by=['CUSTOMER_ID', 'SHOPPING_PT'])\n",
        "\n",
        "# Correct the sequence of SHOPPING_PT to start from 1 for each CUSTOMER_ID\n",
        "df['SHOPPING_PT'] = df.groupby('CUSTOMER_ID').cumcount() + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RuYJH2ALqEp"
      },
      "outputs": [],
      "source": [
        "# Function to handle missing record_type values according to specified rules\n",
        "def fill_missing_record_type(group):\n",
        "    # Ensure group is sorted by 'SHOPPING_PT'\n",
        "    group = group.sort_values('SHOPPING_PT').reset_index(drop=True)\n",
        "\n",
        "    # Handle the last row separately\n",
        "    if pd.isnull(group['RECORD_TYPE'].iloc[-1]):\n",
        "        group['RECORD_TYPE'].iloc[-1] = 1\n",
        "\n",
        "    # Handle the rest of the rows\n",
        "    for i in range(len(group) - 1):\n",
        "        if pd.isnull(group['RECORD_TYPE'].iloc[i]):\n",
        "            group['RECORD_TYPE'].iloc[i] = 0\n",
        "\n",
        "    return group\n",
        "\n",
        "# Apply the function to each group of 'CUSTOMER_ID'\n",
        "df = df.groupby('CUSTOMER_ID', group_keys=False).apply(fill_missing_record_type)\n",
        "\n",
        "# Reset index\n",
        "df.reset_index(drop=True, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCxtNn1rTVJS"
      },
      "outputs": [],
      "source": [
        "def fill_missing_days(df):\n",
        "  # Forward fill missing values within each customer group\n",
        "  df['DAY'] = df.groupby('CUSTOMER_ID')['DAY'].ffill()\n",
        "\n",
        "  # Backward fill missing values within each customer group\n",
        "  df['DAY'] = df.groupby('CUSTOMER_ID')['DAY'].bfill()\n",
        "\n",
        "  # Handling edge cases of leading/trailing NaNs and isolated middle NaNs with different adjacent days\n",
        "  for customer in df['CUSTOMER_ID'].unique():\n",
        "    customer_data = df[df['CUSTOMER_ID'] == customer]\n",
        "\n",
        "    for i in range(1, len(customer_data) - 1):\n",
        "      if pd.isnull(customer_data.iloc[i]['DAY']):\n",
        "        prev_day = customer_data.iloc[i - 1]['DAY']\n",
        "        next_day = customer_data.iloc[i + 1]['DAY']\n",
        "        if prev_day != next_day:\n",
        "          # Fill with the most frequent day within the customer's data\n",
        "          most_frequent_day = customer_data['DAY'].mode().iloc[0]\n",
        "          df.loc[customer_data.index[i], 'DAY'] = most_frequent_day\n",
        "\n",
        "  return df\n",
        "\n",
        "df = fill_missing_days(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTzX4qXnEuon"
      },
      "outputs": [],
      "source": [
        "# Convert 'TIME' to datetime for easier manipulation\n",
        "df['TIME'] = pd.to_datetime(df['TIME'], format='%H:%M:%S', errors='coerce')\n",
        "\n",
        "# Function to handle missing time values according to specified rules\n",
        "def fill_missing_times(group):\n",
        "    # Ensure group is sorted by 'SHOPPING_PT'\n",
        "    group = group.sort_values('SHOPPING_PT')\n",
        "\n",
        "    n = len(group)\n",
        "\n",
        "    # Handle first row\n",
        "    if pd.isnull(group['TIME'].iloc[0]):\n",
        "        if n > 1:\n",
        "            group['TIME'].iloc[0] = group['TIME'].iloc[1] - pd.Timedelta(minutes=2)\n",
        "        else:\n",
        "            group['TIME'].iloc[0] = pd.Timestamp(group['DAY'].iloc[0]) + pd.Timedelta(hours=15, minutes=0, seconds=0)\n",
        "\n",
        "    # Handle middle rows\n",
        "    for i in range(1, n-1):\n",
        "        if pd.isnull(group['TIME'].iloc[i]):\n",
        "            if group['DAY'].iloc[i] == group['DAY'].iloc[i-1]:\n",
        "                group['TIME'].iloc[i] = group['TIME'].iloc[i-1] + pd.Timedelta(minutes=2)\n",
        "            elif group['DAY'].iloc[i] == group['DAY'].iloc[i+1]:\n",
        "                group['TIME'].iloc[i] = group['TIME'].iloc[i+1] - pd.Timedelta(minutes=2)\n",
        "\n",
        "    # Handle last row if more than one row exists\n",
        "    if n > 1 and pd.isnull(group['TIME'].iloc[-1]):\n",
        "        if group['DAY'].iloc[-1] == group['DAY'].iloc[-2]:\n",
        "            group['TIME'].iloc[-1] = group['TIME'].iloc[-2] + pd.Timedelta(minutes=2)\n",
        "        else:\n",
        "            group['TIME'].iloc[-1] = pd.Timestamp(group['DAY'].iloc[-1]) + pd.Timedelta(hours=15, minutes=0, seconds=0)\n",
        "\n",
        "    return group\n",
        "\n",
        "# Apply the function to each group of 'CUSTOMER_ID'\n",
        "df = df.groupby('CUSTOMER_ID', group_keys=False).apply(fill_missing_times)\n",
        "\n",
        "# Convert 'TIME' back to string format\n",
        "df['TIME'] = df['TIME'].dt.strftime('%H:%M:%S')\n",
        "\n",
        "# Reset index\n",
        "df.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NyCDjxPe_Dc",
        "outputId": "0cd4eb9e-b6cd-45b1-da57-5bf67724c4be"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(\"\\nMissing values:\")\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBvqF5LIenTC"
      },
      "outputs": [],
      "source": [
        "df['C_PREVIOUS'].fillna(0, inplace=True)\n",
        "df['DURATION_PREVIOUS'].fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEcnDGAkfCE4",
        "outputId": "a6d6f3f2-0322-469d-85f2-84320e23bd5d"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(\"\\nMissing values:\")\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "K2PF1Zl2S_Cs",
        "outputId": "fe74eed2-562a-4066-ac0e-8889718765de"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPaKup78hlvQ",
        "outputId": "c811a174-d7f5-4128-8fbd-fb408c567ca8"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(\"\\nMissing values:\")\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvTJ7oFhikVB",
        "outputId": "70c1aa94-5744-40dc-e8e5-72c82f8d501d"
      },
      "outputs": [],
      "source": [
        "df['RISK_FACTOR'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBrwF3SLLM8_"
      },
      "outputs": [],
      "source": [
        "df = df.dropna(subset = ['CAR_VALUE','GROUP_SIZE','HOMEOWNER','MARRIED_COUPLE','B','TIME'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uehesRqY6k5E"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Identify features to be used for clustering\n",
        "# features = ['HOMEOWNER', 'GROUP_SIZE', 'CAR_AGE', 'CAR_VALUE', 'AGE_OLDEST', 'AGE_YOUNGEST', 'MARRIED_COUPLE', 'COST']\n",
        "\n",
        "# # Drop rows where any feature for clustering is null, excluding RISK_FACTOR\n",
        "# X = df[features]\n",
        "# X = X.dropna(subset=features)\n",
        "\n",
        "# # Apply KMeans clustering\n",
        "# # scaler = StandardScaler()\n",
        "# # X = scaler.fit_transform(X.drop(columns=['CAR_VALUE']))\n",
        "\n",
        "# # Encode 'CAR_VALUE' after splitting and scaling\n",
        "# le_car_value = LabelEncoder()\n",
        "# X['CAR_VALUE'] = le_car_value.fit_transform(X['CAR_VALUE'].fillna(-1))\n",
        "\n",
        "# # Perform clustering\n",
        "# kmeans = KMeans(n_clusters=4, random_state=42)  # Number of clusters can be adjusted\n",
        "# clusters = kmeans.fit_predict(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQs65neBFp_G"
      },
      "outputs": [],
      "source": [
        "# Add clusters to the dataframe\n",
        "# df.loc[X.index, 'Cluster'] = clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4keT814N8iQM",
        "outputId": "b182f84f-23ff-4bef-b51e-fa8d2a4f44ff"
      },
      "outputs": [],
      "source": [
        "# Separate rows with missing and non-missing RISK_FACTOR\n",
        "missing_risk_factor = df[df['RISK_FACTOR'].isna()]\n",
        "non_missing_risk_factor = df[~df['RISK_FACTOR'].isna()]\n",
        "\n",
        "# Select features for prediction\n",
        "features = ['HOMEOWNER', 'GROUP_SIZE', 'CAR_AGE', 'CAR_VALUE', 'AGE_OLDEST', 'AGE_YOUNGEST', 'MARRIED_COUPLE', 'COST']\n",
        "\n",
        "\n",
        "# Initialize a dictionary to store LabelEncoders\n",
        "label_encoders = {}\n",
        "\n",
        "# Label encode categorical variables\n",
        "for feature in ['CAR_VALUE', 'STATE']:\n",
        "    le = LabelEncoder()\n",
        "    non_missing_risk_factor[feature] = le.fit_transform(non_missing_risk_factor[feature].astype(str))\n",
        "    missing_risk_factor[feature] = le.transform(missing_risk_factor[feature].astype(str))\n",
        "\n",
        "    # Save the fitted LabelEncoder to dictionary\n",
        "    label_encoders[feature] = le\n",
        "\n",
        "# Train a model to predict RISK_FACTOR\n",
        "X = non_missing_risk_factor[features]\n",
        "y = non_missing_risk_factor['RISK_FACTOR']\n",
        "\n",
        "\n",
        "# Ensure y has no missing values and is of correct length\n",
        "assert len(X) == len(y), \"Mismatch in number of samples between X and y\"\n",
        "assert y.isna().sum() == 0, \"y contains missing values\"\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict missing RISK_FACTOR\n",
        "missing_X = missing_risk_factor[features]\n",
        "predicted_risk_factor = model.predict(missing_X)\n",
        "\n",
        "# Assign predicted values back to the dataset\n",
        "missing_risk_factor['RISK_FACTOR'] = predicted_risk_factor\n",
        "\n",
        "# Combine datasets\n",
        "df = pd.concat([non_missing_risk_factor, missing_risk_factor])\n",
        "\n",
        "# Ensure same RISK_FACTOR for each CUSTOMER_ID\n",
        "df['RISK_FACTOR'] = df.groupby('CUSTOMER_ID')['RISK_FACTOR'].transform(lambda x: x.mode()[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GIqJLNWL-CS",
        "outputId": "599f94ab-dfe0-4fe6-de14-c8e6cfef498e"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOlLK-jwNy8S",
        "outputId": "85e4b8b3-a168-4645-92f0-29dc1546e53c"
      },
      "outputs": [],
      "source": [
        "df['STATE'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe-vblOeNwOs",
        "outputId": "36c13969-a4c3-47a2-d834-891f06c4a804"
      },
      "outputs": [],
      "source": [
        "df['CAR_VALUE'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9iHJ2O7MKzz"
      },
      "outputs": [],
      "source": [
        "# Save or use the imputed dataset\n",
        "df.to_csv('preprocessed_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTlobTfsMGhZ",
        "outputId": "e76e2d1d-af12-4d4b-d4d0-7c3b00570be9"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2fYiK3LzWg9x",
        "outputId": "ddfce583-046e-485d-8618-dcd699eb704f"
      },
      "outputs": [],
      "source": [
        "df.head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Cdf8b_BFUZo"
      },
      "outputs": [],
      "source": [
        "# # Function to impute missing RISK_FACTOR\n",
        "# def impute_risk_factor(row):\n",
        "#     if pd.isna(row['RISK_FACTOR']):\n",
        "#         cluster = row['Cluster']\n",
        "#         cluster_data = df[df['Cluster'] == cluster]['RISK_FACTOR'].dropna()\n",
        "#         if not cluster_data.empty:\n",
        "#             # Fix: Directly assign the mode value\n",
        "#             mode_value = mode(cluster_data).mode\n",
        "#         else:\n",
        "#             mode_value = 1  # Default value if no non-missing values are found in the cluster\n",
        "#         return mode_value\n",
        "#     else:\n",
        "#         return row['RISK_FACTOR']\n",
        "\n",
        "# # Apply imputation\n",
        "# df['RISK_FACTOR'] = df.apply(impute_risk_factor, axis=1)\n",
        "\n",
        "# # Ensure consistency within CUSTOMER_ID\n",
        "# customer_ids = df['CUSTOMER_ID'].unique()\n",
        "# for customer_id in customer_ids:\n",
        "#     customer_data = df[df['CUSTOMER_ID'] == customer_id]\n",
        "#     if customer_data['RISK_FACTOR'].isna().any():\n",
        "#         non_na_values = customer_data['RISK_FACTOR'].dropna()\n",
        "#         if not non_na_values.empty:\n",
        "#             # Fix: Directly assign the mode value\n",
        "#             mode_value = mode(non_na_values).mode\n",
        "#         else:\n",
        "#             mode_value = 1  # Default value if no non-missing values are found for the customer\n",
        "#         df.loc[df['CUSTOMER_ID'] == customer_id, 'RISK_FACTOR'] = mode_value\n",
        "\n",
        "# # Drop the Cluster column as it's no longer needed\n",
        "# df.drop(columns=['Cluster'], inplace=True)\n",
        "\n",
        "# print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "id": "a5bb1USAtYv_",
        "outputId": "328e5aa1-1142-4d56-c6cb-60382adcb3c4"
      },
      "outputs": [],
      "source": [
        "# Bivariate analysis: Correlation matrix and heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(df.drop(['TIME'], axis =1).corr(), annot=True, cmap='coolwarm', fmt='.2f', linewidths=.5)\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFMAyUS75A0f"
      },
      "source": [
        "###Preprocessed csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjUBX15hC_Px"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/preprocessed_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzszyzKcDZah"
      },
      "outputs": [],
      "source": [
        "# df= df.drop('Cluster',axis =1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J57l--CryuRO",
        "outputId": "0a40b999-1e9a-4aad-a61a-93fe8b499dc0"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "mte3Yo2SDUU0",
        "outputId": "972a0349-3aa3-4de3-e375-2d24fbf0a91d"
      },
      "outputs": [],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yszsjp5FCXvj"
      },
      "source": [
        "Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Gesr5yNBiOs"
      },
      "outputs": [],
      "source": [
        "# # Assuming df is your DataFrame\n",
        "# categorical_features = ['STATE']\n",
        "# print(categorical_features)\n",
        "# # Label encoding\n",
        "# label_encoder = LabelEncoder()\n",
        "# for col in categorical_features:\n",
        "#     df[col] = label_encoder.fit_transform(df[col])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3wrumkVFZ3Z"
      },
      "source": [
        "###Train-test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wMohdRcE0Mb"
      },
      "outputs": [],
      "source": [
        "# Define target variable\n",
        "target = 'COST'\n",
        "\n",
        "# Train-test split\n",
        "X = df.drop(columns=[target,'TIME','CUSTOMER_ID'])\n",
        "#X = X.dropna()\n",
        "y = df[target]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ckUa0zrpAUd",
        "outputId": "31f6264c-df09-4e3d-d0b0-f3915223d888"
      },
      "outputs": [],
      "source": [
        "X.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IthrhwrFgIa"
      },
      "source": [
        "Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kp21N-adLefa"
      },
      "outputs": [],
      "source": [
        "# Columns to scale\n",
        "columns_to_scale = ['CAR_AGE', 'AGE_OLDEST']\n",
        "\n",
        "# Initialize the MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit the scaler on the training set and transform both training and testing sets\n",
        "X_train[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
        "X_test[columns_to_scale] = scaler.transform(X_test[columns_to_scale])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "CnN_LXBGEFGw",
        "outputId": "46e02ea0-4fdd-41d5-ceb2-218f5c7d0b08"
      },
      "outputs": [],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hSjwVG3W0PfJ",
        "outputId": "599813eb-32aa-4219-94bd-5b0dbcfec7d8"
      },
      "outputs": [],
      "source": [
        "# Correlation Matrix with Heatmap\n",
        "corr_matrix = df.drop('TIME',axis=1).corr()\n",
        "plt.figure(figsize=(20, 12))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Matrix Heatmap')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "g81hSITJ7t7n",
        "outputId": "1c779598-10bc-4612-dae7-a342d3a32c2f"
      },
      "outputs": [],
      "source": [
        "plt.hist(df['COST']); plt.title('Cost of Insurance Policy')\n",
        "plt.xlabel('Cost')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfjYV4FwKklp"
      },
      "source": [
        "###PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZIPian4Kl42",
        "outputId": "fcdd129f-fbdc-43a2-d148-683efaa51ed7"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Columns to scale\n",
        "columns_to_scale = ['CAR_AGE', 'AGE_YOUNGEST', 'AGE_OLDEST']\n",
        "\n",
        "# Initialize the MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit the scaler on the training set and transform both training and testing sets\n",
        "X[columns_to_scale] = scaler.fit_transform(X[columns_to_scale])\n",
        "\n",
        "# Apply PCA\n",
        "n_components = 5  # Number of principal components to keep\n",
        "pca = PCA(n_components=n_components)\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "# Print the explained variance ratio of each principal component\n",
        "print(f\"Explained variance ratio of each principal component: {pca.explained_variance_ratio_}\")\n",
        "\n",
        "# Create a DataFrame with the principal components\n",
        "X_pca_df = pd.DataFrame(X_pca, columns=[f'PC{i+1}' for i in range(n_components)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCHZDbRTLMCW",
        "outputId": "56f01b9d-3662-4ef4-dd44-8f2e61ffe8ca"
      },
      "outputs": [],
      "source": [
        "# Split the PCA-transformed data into training and testing sets\n",
        "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca_df, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize results dictionary\n",
        "results = {}\n",
        "\n",
        "# Train and evaluate each model using the PCA components\n",
        "for name, model in models.items():\n",
        "    # Fit the model on the training data\n",
        "    model.fit(X_train_pca, y_train_pca)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred = model.predict(X_test_pca)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    mae = mean_absolute_error(y_test_pca, y_pred)\n",
        "    mse = mean_squared_error(y_test_pca, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test_pca, y_pred)\n",
        "\n",
        "    # Store the results\n",
        "    results[name] = {\n",
        "        'MAE': mae,\n",
        "        'MSE': mse,\n",
        "        'RMSE': rmse,\n",
        "        'R2': r2\n",
        "    }\n",
        "\n",
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame(results).T  # Transpose for better formatting\n",
        "\n",
        "# Print the results\n",
        "print(results_df)\n",
        "\n",
        "# Save results to a CSV file\n",
        "results_df.to_csv('model_evaluation_results_pca.csv', index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "iGKSQN_VLTo6",
        "outputId": "94302e0f-7a44-4543-9501-9c7517a5bab4"
      },
      "outputs": [],
      "source": [
        "# Plot comparison of R2 scores\n",
        "plt.figure(figsize=(12, 6))\n",
        "model_names = list(results.keys())\n",
        "r2_scores = [results[name]['R2'] for name in model_names]\n",
        "sns.barplot(x=model_names, y=r2_scores)\n",
        "plt.title('Comparison of R-squared Scores')\n",
        "plt.ylabel('R-squared Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rADULqK2BgtI"
      },
      "source": [
        "###K-best, 13 features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BI1YrtQJ0aVo",
        "outputId": "31f7e871-3772-4fcf-8dcc-3811c33191e1"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "# Univariate Selection\n",
        "select_kbest = SelectKBest(score_func=f_regression, k=13)\n",
        "fit = select_kbest.fit(X, y)\n",
        "feature_scores = pd.DataFrame({'Feature': X.columns, 'Score': fit.scores_})\n",
        "print(\"Univariate Selection:\")\n",
        "print(feature_scores.nlargest(13, 'Score'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH6lhSlG0-G4",
        "outputId": "14cd720b-9dc0-4f02-d6b7-ee761a61f0a3"
      },
      "outputs": [],
      "source": [
        "# Univariate Selection\n",
        "select_kbest = SelectKBest(score_func=f_regression, k=13)\n",
        "fit = select_kbest.fit(X, y)\n",
        "selected_features = X.columns[fit.get_support()]\n",
        "print(f\"Selected features from Univariate Selection: {selected_features}\")\n",
        "\n",
        "# Subset the data with selected features\n",
        "X_selected = X[selected_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGtoPjDJ1zui"
      },
      "outputs": [],
      "source": [
        "# Subset the data with selected features\n",
        "X_selected = X[selected_features]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWoQCU6BBSmN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWex3XOQ0d9J"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# # Feature Importance from Random Forest\n",
        "# model_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "# model_rf.fit(X, y)\n",
        "# importances = model_rf.feature_importances_\n",
        "# feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
        "# print(\"\\nFeature Importance from Random Forest:\")\n",
        "# print(feature_importances.sort_values(by='Importance', ascending=False))\n",
        "\n",
        "# # Lasso Regularization (L1 Regularization)\n",
        "# model_lasso = Lasso(alpha=0.01)\n",
        "# model_lasso.fit(X, y)\n",
        "# lasso_coef = pd.DataFrame({'Feature': X.columns, 'Coefficient': model_lasso.coef_})\n",
        "# print(\"\\nLasso Regularization:\")\n",
        "# print(lasso_coef[lasso_coef['Coefficient'] != 0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1aY7LdVEbxe"
      },
      "outputs": [],
      "source": [
        "# with pd.option_context('display.max_columns', None):\n",
        "#   print(X_train.head(25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yzJ0CNHzGOV"
      },
      "outputs": [],
      "source": [
        "# Models to evaluate\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge Regression': Ridge(),\n",
        "    'Lasso Regression': Lasso(),\n",
        "    'Decision Tree': DecisionTreeRegressor(),\n",
        "    'Random Forest': RandomForestRegressor(),\n",
        "    'Gradient Boosting': GradientBoostingRegressor()\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qFO4iP8zm3Y"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Initialize results dictionary\n",
        "results = {}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name, model in models.items():\n",
        "    # Fit the model on the training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Store the results\n",
        "    results[name] = {\n",
        "        'MAE': mae,\n",
        "        'MSE': mse,\n",
        "        'RMSE': rmse,\n",
        "        'R2': r2\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "TM-l5rME2-R9",
        "outputId": "9bc5f5b6-1459-4b1f-b343-82902d8ad37b"
      },
      "outputs": [],
      "source": [
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame(results).T  # Transpose for better formatting\n",
        "\n",
        "# Save results to a CSV file\n",
        "results_df.to_csv('model_evaluation_results_kbest_final.csv', index=True)\n",
        "\n",
        "# Display the results as a table\n",
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "a5Vss9eMzrLu",
        "outputId": "41a7136e-f22c-401f-e84d-ed02c0d802d9"
      },
      "outputs": [],
      "source": [
        "# Plot comparison of R2 scores\n",
        "plt.figure(figsize=(12, 6))\n",
        "model_names = list(results.keys())\n",
        "r2_scores = [results[name]['R2'] for name in model_names]\n",
        "sns.barplot(x=model_names, y=r2_scores)\n",
        "plt.title('Comparison of R-squared Scores')\n",
        "plt.ylabel('R-squared Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTUAwijxzuAm",
        "outputId": "f5409b61-2297-497f-ed03-765190c3bfde"
      },
      "outputs": [],
      "source": [
        "# Fit the best model (Random Forest in this case) on the entire training data\n",
        "best_model = RandomForestRegressor()\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions and evaluation on the training set\n",
        "train_predictions = best_model.predict(X_train)\n",
        "train_mae = mean_absolute_error(y_train, train_predictions)\n",
        "train_mse = mean_squared_error(y_train, train_predictions)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "train_r2 = r2_score(y_train, train_predictions)\n",
        "\n",
        "print(f\"Train Set Evaluation for Random Forest:\")\n",
        "print(f\"  MAE: {train_mae}\")\n",
        "print(f\"  MSE: {train_mse}\")\n",
        "print(f\"  RMSE: {train_rmse}\")\n",
        "print(f\"  R2: {train_r2}\")\n",
        "\n",
        "# Predictions and evaluation on the test set\n",
        "test_predictions = best_model.predict(X_test)\n",
        "test_mae = mean_absolute_error(y_test, test_predictions)\n",
        "test_mse = mean_squared_error(y_test, test_predictions)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "test_r2 = r2_score(y_test, test_predictions)\n",
        "\n",
        "print(f\"\\nTest Set Evaluation for Random Forest:\")\n",
        "print(f\"  MAE: {test_mae}\")\n",
        "print(f\"  MSE: {test_mse}\")\n",
        "print(f\"  RMSE: {test_rmse}\")\n",
        "print(f\"  R2: {test_r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foMlqJFKg7GU",
        "outputId": "44ee1831-4a12-43ca-d1e6-832e3e6d6696"
      },
      "outputs": [],
      "source": [
        "# Create DataFrame with features, actual and predicted values for test set\n",
        "test_results = pd.DataFrame(X_test, columns=columns_to_scale)\n",
        "test_results['Actual'] = y_test.values\n",
        "test_results['Predicted'] = test_predictions\n",
        "\n",
        "print(\"\\nSample of Test Results:\")\n",
        "print(test_results.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "RE2eYP-cg9me",
        "outputId": "339974fe-2dc0-4ed2-9a35-0c50ce3a9dd7"
      },
      "outputs": [],
      "source": [
        "# Compare metrics between train and test sets\n",
        "metrics_comparison = pd.DataFrame({\n",
        "    'Metric': ['MAE', 'MSE', 'RMSE', 'R2'],\n",
        "    'Train': [train_mae, train_mse, train_rmse, train_r2],\n",
        "    'Test': [test_mae, test_mse, test_rmse, test_r2]\n",
        "})\n",
        "\n",
        "# Save results to a CSV file\n",
        "metrics_comparison.to_csv('best_model_metrics.csv', index=True)\n",
        "print(\"\\nMetrics Comparison:\")\n",
        "metrics_comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "mg3jFB6shC4c",
        "outputId": "57150d0c-fb0e-4997-bb7c-c299f64e0eee"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Visualize the metrics comparison\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Metric', y='value', hue='variable', data=pd.melt(metrics_comparison, ['Metric']))\n",
        "plt.title('Metrics Comparison between Train and Test Sets')\n",
        "plt.ylabel('Value')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEpCU2Q-wAIO"
      },
      "source": [
        "###Manual FS , 15 features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZbBqmWuvs56"
      },
      "outputs": [],
      "source": [
        "selected_features = ['RECORD_TYPE','STATE','GROUP_SIZE','HOMEOWNER','CAR_AGE','CAR_VALUE','RISK_FACTOR',\n",
        "                     'MARRIED_COUPLE','AGE_OLDEST','C_PREVIOUS', 'A' ,'B','C','D','E','F' ,'G']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxw-QEKvYsrB",
        "outputId": "516e001b-f15d-4869-be00-50371077b81d"
      },
      "outputs": [],
      "source": [
        "len(selected_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlysWpXwvftu"
      },
      "outputs": [],
      "source": [
        "    # Define target variable\n",
        "target = 'COST'\n",
        "# Subset the data with selected features\n",
        "X_selected = df[selected_features]\n",
        "y = df[target]\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKRdftmMO4Q7",
        "outputId": "c15155e7-4ab5-49ef-dc7b-b0091595699e"
      },
      "outputs": [],
      "source": [
        "X_selected.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOvbnSyzS8D8",
        "outputId": "072860fb-03c8-4f79-9158-0b2d55846012"
      },
      "outputs": [],
      "source": [
        "X_selected.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "tOs6uU4MCzq1",
        "outputId": "f9f1ce6e-c2b6-4dfe-e398-815c0164879a"
      },
      "outputs": [],
      "source": [
        "X_selected.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cC_0tXQCxWw"
      },
      "outputs": [],
      "source": [
        "# Columns to scale\n",
        "columns_to_scale = ['CAR_AGE', 'AGE_OLDEST']\n",
        "\n",
        "# Initialize the MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit the scaler on the training set and transform both training and testing sets\n",
        "X_train[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
        "X_test[columns_to_scale] = scaler.transform(X_test[columns_to_scale])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FB4mUU4uvfty",
        "outputId": "6d360f61-dec5-47a1-9d64-fe443c4e9dd2"
      },
      "outputs": [],
      "source": [
        "# Fit the best model (Random Forest in this case) on the entire training data\n",
        "best_model = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions and evaluation on the training set\n",
        "train_predictions = best_model.predict(X_train)\n",
        "train_mae = mean_absolute_error(y_train, train_predictions)\n",
        "train_mse = mean_squared_error(y_train, train_predictions)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "train_r2 = r2_score(y_train, train_predictions)\n",
        "\n",
        "print(f\"Train Set Evaluation for Random Forest:\")\n",
        "print(f\"  MAE: {train_mae}\")\n",
        "print(f\"  MSE: {train_mse}\")\n",
        "print(f\"  RMSE: {train_rmse}\")\n",
        "print(f\"  R2: {train_r2}\")\n",
        "\n",
        "# Predictions and evaluation on the test set\n",
        "test_predictions = best_model.predict(X_test)\n",
        "test_mae = mean_absolute_error(y_test, test_predictions)\n",
        "test_mse = mean_squared_error(y_test, test_predictions)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "test_r2 = r2_score(y_test, test_predictions)\n",
        "\n",
        "print(f\"\\nTest Set Evaluation for Random Forest:\")\n",
        "print(f\"  MAE: {test_mae}\")\n",
        "print(f\"  MSE: {test_mse}\")\n",
        "print(f\"  RMSE: {test_rmse}\")\n",
        "print(f\"  R2: {test_r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nPEOmlqvfty",
        "outputId": "f045cc22-32f5-4234-a0e1-4d7fd7358f1d"
      },
      "outputs": [],
      "source": [
        "# Create DataFrame with features, actual and predicted values for test set\n",
        "test_results = pd.DataFrame(X_test, columns=selected_features)\n",
        "test_results['Actual'] = y_test.values\n",
        "test_results['Predicted'] = test_predictions\n",
        "\n",
        "print(\"\\nSample of Test Results:\")\n",
        "print(test_results.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "nut1hUkQvftz",
        "outputId": "88bbda6e-ca48-44fd-aae5-9a8de97d96a4"
      },
      "outputs": [],
      "source": [
        "# Compare metrics between train and test sets\n",
        "metrics_comparison = pd.DataFrame({\n",
        "    'Metric': ['MAE', 'MSE', 'RMSE', 'R2'],\n",
        "    'Train': [train_mae, train_mse, train_rmse, train_r2],\n",
        "    'Test': [test_mae, test_mse, test_rmse, test_r2]\n",
        "})\n",
        "\n",
        "# # Save results to a CSV file\n",
        "# metrics_comparison.to_csv('best_model_metrics_trial02.csv', index=True)\n",
        "print(\"\\nMetrics Comparison:\")\n",
        "metrics_comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "f27n_cVcvftz",
        "outputId": "5439a364-d19b-40e7-eb25-b34b4aaee0f8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Visualize the metrics comparison\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Metric', y='value', hue='variable', data=pd.melt(metrics_comparison, ['Metric']))\n",
        "plt.title('Metrics Comparison between Train and Test Sets')\n",
        "plt.ylabel('Value')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAertoIyv877"
      },
      "source": [
        "###RFR - hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTDEC6ThqdIR"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mbmr83tQqkKP"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Define the model\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300, 400, 500],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ua4ZZZNbqnXj",
        "outputId": "2d880502-6274-45ef-9a22-56aaf8a31e38"
      },
      "outputs": [],
      "source": [
        "# Create the randomized search cross-validation object\n",
        "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=50, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
        "\n",
        "# Fit on the training data\n",
        "rf_random.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(\"Best Parameters found:\")\n",
        "print(rf_random.best_params_)\n",
        "print(\"\\nBest Score found:\")\n",
        "print(rf_random.best_score_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9I62JAQr1eK"
      },
      "outputs": [],
      "source": [
        "# 5. Evaluate on training set\n",
        "train_predictions = rf_random.best_estimator_.predict(X_train)\n",
        "train_mae = mean_absolute_error(y_train, train_predictions)\n",
        "train_mse = mean_squared_error(y_train, train_predictions)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "train_r2 = r2_score(y_train, train_predictions)\n",
        "\n",
        "print(f\"Train Set Evaluation for Random Forest:\")\n",
        "print(f\"  MAE: {train_mae}\")\n",
        "print(f\"  MSE: {train_mse}\")\n",
        "print(f\"  RMSE: {train_rmse}\")\n",
        "print(f\"  R2: {train_r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFrZwd_KqpxX"
      },
      "outputs": [],
      "source": [
        "# Evaluate on validation set\n",
        "val_predictions = rf_random.best_estimator_.predict(X_val)\n",
        "val_mae = mean_absolute_error(y_val, val_predictions)\n",
        "val_mse = mean_squared_error(y_val, val_predictions)\n",
        "val_rmse = np.sqrt(val_mse)\n",
        "val_r2 = r2_score(y_val, val_predictions)\n",
        "\n",
        "print(f\"Validation Set Evaluation for Random Forest:\")\n",
        "print(f\"  MAE: {val_mae}\")\n",
        "print(f\"  MSE: {val_mse}\")\n",
        "print(f\"  RMSE: {val_rmse}\")\n",
        "print(f\"  R2: {val_r2}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdGUN-HIqslr"
      },
      "outputs": [],
      "source": [
        "# Predictions and evaluation on the test set\n",
        "test_predictions = rf_random.best_estimator_.predict(X_test)\n",
        "test_mae = mean_absolute_error(y_test, test_predictions)\n",
        "test_mse = mean_squared_error(y_test, test_predictions)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "test_r2 = r2_score(y_test, test_predictions)\n",
        "\n",
        "print(f\"\\nTest Set Evaluation for Random Forest (after tuning):\")\n",
        "print(f\"  MAE: {test_mae}\")\n",
        "print(f\"  MSE: {test_mse}\")\n",
        "print(f\"  RMSE: {test_rmse}\")\n",
        "print(f\"  R2: {test_r2}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TKh2i3trf0v"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you have metrics variables defined (e.g., val_mae, val_mse, etc.)\n",
        "\n",
        "# Create a DataFrame with metrics results\n",
        "metrics_results = pd.DataFrame({\n",
        "    'Metric': ['MAE', 'MSE', 'RMSE', 'R2'],\n",
        "    'Training': [train_mae, train_mse, train_rmse, train_r2],\n",
        "    'Validation': [val_mae, val_mse, val_rmse, val_r2],\n",
        "    'Test': [test_mae, test_mse, test_rmse, test_r2]\n",
        "})\n",
        "\n",
        "# Save metrics results to CSV\n",
        "metrics_results.to_csv('metrics_results_hyperparam.csv', index=False)\n",
        "\n",
        "print(\"Metrics results saved successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ0xrIpyEsfe"
      },
      "source": [
        "###K-best , 18 features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-jLbRcaEsfk",
        "outputId": "bb35281a-9e19-4047-9157-b3e448388e51"
      },
      "outputs": [],
      "source": [
        "# Univariate Selection\n",
        "select_kbest = SelectKBest(score_func=f_regression, k=18)\n",
        "fit = select_kbest.fit(X, y)\n",
        "selected_features = X.columns[fit.get_support()]\n",
        "print(f\"Selected features from Univariate Selection: {selected_features}\")\n",
        "\n",
        "# Subset the data with selected features\n",
        "X_selected = X[selected_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQYyYU0qEsfl"
      },
      "outputs": [],
      "source": [
        "# Subset the data with selected features\n",
        "X_selected = X[selected_features]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFNOIlOkEsfl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OisGArjwEsfl"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# # Feature Importance from Random Forest\n",
        "# model_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "# model_rf.fit(X, y)\n",
        "# importances = model_rf.feature_importances_\n",
        "# feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
        "# print(\"\\nFeature Importance from Random Forest:\")\n",
        "# print(feature_importances.sort_values(by='Importance', ascending=False))\n",
        "\n",
        "# # Lasso Regularization (L1 Regularization)\n",
        "# model_lasso = Lasso(alpha=0.01)\n",
        "# model_lasso.fit(X, y)\n",
        "# lasso_coef = pd.DataFrame({'Feature': X.columns, 'Coefficient': model_lasso.coef_})\n",
        "# print(\"\\nLasso Regularization:\")\n",
        "# print(lasso_coef[lasso_coef['Coefficient'] != 0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9ysOHqPEsfm"
      },
      "outputs": [],
      "source": [
        "# with pd.option_context('display.max_columns', None):\n",
        "#   print(X_train.head(25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znfOwitPEsfm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Models to evaluate\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge Regression': Ridge(),\n",
        "    'Lasso Regression': Lasso(),\n",
        "    'Decision Tree': DecisionTreeRegressor(),\n",
        "    'Random Forest': RandomForestRegressor(),\n",
        "    'Gradient Boosting': GradientBoostingRegressor()\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBKONSjOEsfm"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Initialize results dictionary\n",
        "results = {}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name, model in models.items():\n",
        "    # Fit the model on the training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Store the results\n",
        "    results[name] = {\n",
        "        'MAE': mae,\n",
        "        'MSE': mse,\n",
        "        'RMSE': rmse,\n",
        "        'R2': r2\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "ItWaIUImEsfn",
        "outputId": "9c9b8886-4337-4822-b136-dec3508b001f"
      },
      "outputs": [],
      "source": [
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame(results).T  # Transpose for better formatting\n",
        "\n",
        "# Save results to a CSV file\n",
        "results_df.to_csv('model_evaluation_results_kbest_18.csv', index=True)\n",
        "\n",
        "# Display the results as a table\n",
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "OlYxlQenEsfo",
        "outputId": "11f8a64e-c7d9-4989-90d1-7266d1fbd65a"
      },
      "outputs": [],
      "source": [
        "# Plot comparison of R2 scores\n",
        "plt.figure(figsize=(12, 6))\n",
        "model_names = list(results.keys())\n",
        "r2_scores = [results[name]['R2'] for name in model_names]\n",
        "sns.barplot(x=model_names, y=r2_scores)\n",
        "plt.title('Comparison of R-squared Scores')\n",
        "plt.ylabel('R-squared Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02HdWL2yEsfp"
      },
      "outputs": [],
      "source": [
        "# # Fit the best model (Random Forest in this case) on the entire training data\n",
        "# best_model = RandomForestRegressor()\n",
        "# best_model.fit(X_train, y_train)\n",
        "\n",
        "# # Predictions and evaluation on the test set\n",
        "# test_predictions = best_model.predict(X_test)\n",
        "# test_mae = mean_absolute_error(y_test, test_predictions)\n",
        "# test_mse = mean_squared_error(y_test, test_predictions)\n",
        "# test_rmse = np.sqrt(test_mse)\n",
        "# test_r2 = r2_score(y_test, test_predictions)\n",
        "\n",
        "# print(f\"Test Set Evaluation for Random Forest:\")\n",
        "# print(f\"  MAE: {test_mae}\")\n",
        "# print(f\"  MSE: {test_mse}\")\n",
        "# print(f\"  RMSE: {test_rmse}\")\n",
        "# print(f\"  R2: {test_r2}\")\n",
        "\n",
        "# # Create DataFrame with features, actual and predicted values for test set\n",
        "# test_results = pd.DataFrame(X_test, columns=columns_to_scale)\n",
        "# test_results['Actual'] = y_test.values\n",
        "# test_results['Predicted'] = test_predictions\n",
        "\n",
        "# print(\"\\nSample of Test Results:\")\n",
        "# print(test_results.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gvNvUPJBmGa"
      },
      "source": [
        "###RFE, 15 features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiWase3tBxDY",
        "outputId": "e71898e2-e011-49ac-b591-dcc7e61548ee"
      },
      "outputs": [],
      "source": [
        "# Recursive Feature Elimination (RFE)\n",
        "model_lr = LinearRegression()\n",
        "rfe = RFE(model_lr, n_features_to_select=15)\n",
        "fit = rfe.fit(X, y)\n",
        "selected_features = pd.DataFrame({'Feature': X.columns, 'Selected': fit.support_, 'Ranking': fit.ranking_})\n",
        "print(\"\\nRecursive Feature Elimination:\")\n",
        "print(selected_features[selected_features['Selected'] == True])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxfP_0L5CLAI"
      },
      "outputs": [],
      "source": [
        "# Extract the names of the selected features\n",
        "selected_feature_names = selected_features[selected_features['Selected'] == True]['Feature'].tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NwY470ABmGf"
      },
      "outputs": [],
      "source": [
        "# Subset the data with selected features\n",
        "X_selected = X[selected_feature_names]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "me2JbszNBmGg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czdxZZelBmGg"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# # Feature Importance from Random Forest\n",
        "# model_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "# model_rf.fit(X, y)\n",
        "# importances = model_rf.feature_importances_\n",
        "# feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
        "# print(\"\\nFeature Importance from Random Forest:\")\n",
        "# print(feature_importances.sort_values(by='Importance', ascending=False))\n",
        "\n",
        "# # Lasso Regularization (L1 Regularization)\n",
        "# model_lasso = Lasso(alpha=0.01)\n",
        "# model_lasso.fit(X, y)\n",
        "# lasso_coef = pd.DataFrame({'Feature': X.columns, 'Coefficient': model_lasso.coef_})\n",
        "# print(\"\\nLasso Regularization:\")\n",
        "# print(lasso_coef[lasso_coef['Coefficient'] != 0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-lXNpqOBmGi",
        "outputId": "9ed6a251-7cb2-4533-f705-f3439b799a06"
      },
      "outputs": [],
      "source": [
        "# with pd.option_context('display.max_columns', None):\n",
        "#   print(X_train.head(25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Jr_ZapUBmGj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Models to evaluate\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge Regression': Ridge(),\n",
        "    'Lasso Regression': Lasso(),\n",
        "    'Decision Tree': DecisionTreeRegressor(),\n",
        "    'Random Forest': RandomForestRegressor(),\n",
        "    'Gradient Boosting': GradientBoostingRegressor()\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxdLNtLvBmGk"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Initialize results dictionary\n",
        "results = {}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name, model in models.items():\n",
        "    # Fit the model on the training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Store the results\n",
        "    results[name] = {\n",
        "        'MAE': mae,\n",
        "        'MSE': mse,\n",
        "        'RMSE': rmse,\n",
        "        'R2': r2\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "GQvueZXxBmGk",
        "outputId": "33f17763-e37d-468c-c408-cc8f2216c037"
      },
      "outputs": [],
      "source": [
        "# Convert results to a DataFrame\n",
        "results_df_rfe = pd.DataFrame(results).T  # Transpose for better formatting\n",
        "\n",
        "# Save results to a CSV file\n",
        "results_df_rfe.to_csv('model_evaluation_results_rfe.csv', index=True)\n",
        "\n",
        "# Display the results as a table\n",
        "results_df_rfe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "ouqL0A3uBmGk",
        "outputId": "09839815-80d0-4053-aa12-179e44a1b39f"
      },
      "outputs": [],
      "source": [
        "# Plot comparison of R2 scores\n",
        "plt.figure(figsize=(12, 6))\n",
        "model_names = list(results.keys())\n",
        "r2_scores = [results[name]['R2'] for name in model_names]\n",
        "sns.barplot(x=model_names, y=r2_scores)\n",
        "plt.title('Comparison of R-squared Scores')\n",
        "plt.ylabel('R-squared Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agT4tEEcBmGl"
      },
      "outputs": [],
      "source": [
        "# Fit the best model (Random Forest in this case) on the entire training data\n",
        "best_model = RandomForestRegressor()\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions and evaluation on the test set\n",
        "test_predictions = best_model.predict(X_test)\n",
        "test_mae = mean_absolute_error(y_test, test_predictions)\n",
        "test_mse = mean_squared_error(y_test, test_predictions)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "test_r2 = r2_score(y_test, test_predictions)\n",
        "\n",
        "print(f\"Test Set Evaluation for Random Forest:\")\n",
        "print(f\"  MAE: {test_mae}\")\n",
        "print(f\"  MSE: {test_mse}\")\n",
        "print(f\"  RMSE: {test_rmse}\")\n",
        "print(f\"  R2: {test_r2}\")\n",
        "\n",
        "# Create DataFrame with features, actual and predicted values for test set\n",
        "test_results = pd.DataFrame(X_test, columns=columns_to_scale)\n",
        "test_results['Actual'] = y_test.values\n",
        "test_results['Predicted'] = test_predictions\n",
        "\n",
        "print(\"\\nSample of Test Results:\")\n",
        "print(test_results.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wOG150FBmGl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GAWG0OgHUUk"
      },
      "source": [
        "###RFE , 18 features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXC7-q3yHUUm",
        "outputId": "8fc8d882-fafc-4466-92eb-39b5b8068564"
      },
      "outputs": [],
      "source": [
        "# Recursive Feature Elimination (RFE)\n",
        "model_lr = LinearRegression()\n",
        "rfe = RFE(model_lr, n_features_to_select=18)\n",
        "fit = rfe.fit(X, y)\n",
        "selected_features = pd.DataFrame({'Feature': X.columns, 'Selected': fit.support_, 'Ranking': fit.ranking_})\n",
        "print(\"\\nRecursive Feature Elimination:\")\n",
        "print(selected_features[selected_features['Selected'] == True])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HRzb012HUUn"
      },
      "outputs": [],
      "source": [
        "# Extract the names of the selected features\n",
        "selected_feature_names = selected_features[selected_features['Selected'] == True]['Feature'].tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkMwDT4BHUUo"
      },
      "outputs": [],
      "source": [
        "# Subset the data with selected features\n",
        "X_selected = X[selected_feature_names]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1aUWHmsHUUp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0H-xktAxHUUq"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# # Feature Importance from Random Forest\n",
        "# model_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "# model_rf.fit(X, y)\n",
        "# importances = model_rf.feature_importances_\n",
        "# feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
        "# print(\"\\nFeature Importance from Random Forest:\")\n",
        "# print(feature_importances.sort_values(by='Importance', ascending=False))\n",
        "\n",
        "# # Lasso Regularization (L1 Regularization)\n",
        "# model_lasso = Lasso(alpha=0.01)\n",
        "# model_lasso.fit(X, y)\n",
        "# lasso_coef = pd.DataFrame({'Feature': X.columns, 'Coefficient': model_lasso.coef_})\n",
        "# print(\"\\nLasso Regularization:\")\n",
        "# print(lasso_coef[lasso_coef['Coefficient'] != 0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIIm_nO6HUUq"
      },
      "outputs": [],
      "source": [
        "# with pd.option_context('display.max_columns', None):\n",
        "#   print(X_train.head(25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBt9CDOXHUUr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Models to evaluate\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge Regression': Ridge(),\n",
        "    'Lasso Regression': Lasso(),\n",
        "    'Decision Tree': DecisionTreeRegressor(),\n",
        "    'Random Forest': RandomForestRegressor(),\n",
        "    'Gradient Boosting': GradientBoostingRegressor()\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZndX9USnHUUr"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Initialize results dictionary\n",
        "results = {}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name, model in models.items():\n",
        "    # Fit the model on the training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Store the results\n",
        "    results[name] = {\n",
        "        'MAE': mae,\n",
        "        'MSE': mse,\n",
        "        'RMSE': rmse,\n",
        "        'R2': r2\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "EHgOVejKHUUs",
        "outputId": "95c860f8-e9ff-491b-a941-aa8db517c226"
      },
      "outputs": [],
      "source": [
        "# Convert results to a DataFrame\n",
        "results_df_rfe = pd.DataFrame(results).T  # Transpose for better formatting\n",
        "\n",
        "# Save results to a CSV file\n",
        "results_df_rfe.to_csv('model_evaluation_results_rfe_18.csv', index=True)\n",
        "\n",
        "# Display the results as a table\n",
        "results_df_rfe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "brX_A0EMHUUs",
        "outputId": "f730f813-e75f-48e9-e90d-a2b830c9140b"
      },
      "outputs": [],
      "source": [
        "# Plot comparison of R2 scores\n",
        "plt.figure(figsize=(12, 6))\n",
        "model_names = list(results.keys())\n",
        "r2_scores = [results[name]['R2'] for name in model_names]\n",
        "sns.barplot(x=model_names, y=r2_scores)\n",
        "plt.title('Comparison of R-squared Scores')\n",
        "plt.ylabel('R-squared Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3BP5saHHUUt"
      },
      "outputs": [],
      "source": [
        "# # Fit the best model (Random Forest in this case) on the entire training data\n",
        "# best_model = RandomForestRegressor()\n",
        "# best_model.fit(X_train, y_train)\n",
        "\n",
        "# # Predictions and evaluation on the test set\n",
        "# test_predictions = best_model.predict(X_test)\n",
        "# test_mae = mean_absolute_error(y_test, test_predictions)\n",
        "# test_mse = mean_squared_error(y_test, test_predictions)\n",
        "# test_rmse = np.sqrt(test_mse)\n",
        "# test_r2 = r2_score(y_test, test_predictions)\n",
        "\n",
        "# print(f\"Test Set Evaluation for Random Forest:\")\n",
        "# print(f\"  MAE: {test_mae}\")\n",
        "# print(f\"  MSE: {test_mse}\")\n",
        "# print(f\"  RMSE: {test_rmse}\")\n",
        "# print(f\"  R2: {test_r2}\")\n",
        "\n",
        "# # Create DataFrame with features, actual and predicted values for test set\n",
        "# test_results = pd.DataFrame(X_test, columns=columns_to_scale)\n",
        "# test_results['Actual'] = y_test.values\n",
        "# test_results['Predicted'] = test_predictions\n",
        "\n",
        "# print(\"\\nSample of Test Results:\")\n",
        "# print(test_results.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hc-rczoCHUUt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4blFKeK-44E9"
      },
      "source": [
        "###Extra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "cTlbEudWH3V9",
        "outputId": "9a51b0b1-e314-4df9-daee-e01528b9583e"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Linear Regression\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Sy0XHkSaD8o"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "# import numpy as np\n",
        "\n",
        "# # Function to evaluate model and return metrics\n",
        "# def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
        "#     # Predictions\n",
        "#     train_predictions = model.predict(X_train)\n",
        "#     test_predictions = model.predict(X_test)\n",
        "\n",
        "#     # MAE, MSE, RMSE, R2 for training set\n",
        "#     train_mae = mean_absolute_error(y_train, train_predictions)\n",
        "#     train_mse = mean_squared_error(y_train, train_predictions)\n",
        "#     train_rmse = np.sqrt(train_mse)\n",
        "#     train_r2 = r2_score(y_train, train_predictions)\n",
        "\n",
        "#     # MAE, MSE, RMSE, R2 for test set\n",
        "#     test_mae = mean_absolute_error(y_test, test_predictions)\n",
        "#     test_mse = mean_squared_error(y_test, test_predictions)\n",
        "#     test_rmse = np.sqrt(test_mse)\n",
        "#     test_r2 = r2_score(y_test, test_predictions)\n",
        "\n",
        "#     return train_mae, train_mse, train_rmse, train_r2, test_mae, test_mse, test_rmse, test_r2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uEzPZIbaHRG",
        "outputId": "31d3e6b7-6730-49d9-9323-f71919531238"
      },
      "outputs": [],
      "source": [
        "# # Evaluate Linear Regression model\n",
        "# lr_train_mae, lr_train_mse, lr_train_rmse, lr_train_r2, lr_test_mae, lr_test_mse, lr_test_rmse, lr_test_r2 = \\\n",
        "#     evaluate_model(lr_model, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# # Evaluate Random Forest model\n",
        "# rf_train_mae, rf_train_mse, rf_train_rmse, rf_train_r2, rf_test_mae, rf_test_mse, rf_test_rmse, rf_test_r2 = \\\n",
        "#     evaluate_model(rf_model, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# # Print metrics for both models\n",
        "# print(\"Linear Regression Metrics:\")\n",
        "# print(f\"  Train MAE: {lr_train_mae}, MSE: {lr_train_mse}, RMSE: {lr_train_rmse}, R2: {lr_train_r2}\")\n",
        "# print(f\"  Test MAE: {lr_test_mae}, MSE: {lr_test_mse}, RMSE: {lr_test_rmse}, R2: {lr_test_r2}\")\n",
        "\n",
        "# print(\"\\nRandom Forest Metrics:\")\n",
        "# print(f\"  Train MAE: {rf_train_mae}, MSE: {rf_train_mse}, RMSE: {rf_train_rmse}, R2: {rf_train_r2}\")\n",
        "# print(f\"  Test MAE: {rf_test_mae}, MSE: {rf_test_mse}, RMSE: {rf_test_rmse}, R2: {rf_test_r2}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wKusCfy67Rs",
        "outputId": "8d1be129-99f2-489f-e34f-14e2ba57c2ed"
      },
      "outputs": [],
      "source": [
        "X_test.columns.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HzuXFims_PP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to evaluate model and return metrics and predictions\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test, feature_names):\n",
        "    # Predictions\n",
        "    train_predictions = model.predict(X_train)\n",
        "    test_predictions = model.predict(X_test)\n",
        "\n",
        "    # MAE, MSE, RMSE, R2 for training set\n",
        "    train_mae = mean_absolute_error(y_train, train_predictions)\n",
        "    train_mse = mean_squared_error(y_train, train_predictions)\n",
        "    train_rmse = np.sqrt(train_mse)\n",
        "    train_r2 = r2_score(y_train, train_predictions)\n",
        "\n",
        "    # MAE, MSE, RMSE, R2 for test set\n",
        "    test_mae = mean_absolute_error(y_test, test_predictions)\n",
        "    test_mse = mean_squared_error(y_test, test_predictions)\n",
        "    test_rmse = np.sqrt(test_mse)\n",
        "    test_r2 = r2_score(y_test, test_predictions)\n",
        "\n",
        "    # Create DataFrame with features, actual and predicted values for train and test sets\n",
        "    train_results = pd.DataFrame(X_train, columns=feature_names)\n",
        "    train_results['Actual'] = y_train\n",
        "    train_results['Predicted'] = train_predictions\n",
        "\n",
        "    test_results = pd.DataFrame(X_test, columns=feature_names)\n",
        "    test_results['Actual'] = y_test\n",
        "    test_results['Predicted'] = test_predictions\n",
        "\n",
        "    return (train_mae, train_mse, train_rmse, train_r2, test_mae, test_mse, test_rmse, test_r2,\n",
        "            train_results, test_results)\n",
        "\n",
        "# Feature names\n",
        "feature_names = X_train.columns.to_list()\n",
        "#  ['HOMEOWNER', 'GROUP_SIZE', 'CAR_AGE', 'CAR_VALUE', 'AGE_OLDEST', 'AGE_YOUNGEST', 'MARRIED_COUPLE']\n",
        "\n",
        "# Evaluate Linear Regression model\n",
        "(lr_train_mae, lr_train_mse, lr_train_rmse, lr_train_r2, lr_test_mae, lr_test_mse, lr_test_rmse, lr_test_r2,\n",
        " lr_train_results, lr_test_results) = evaluate_model(lr_model, X_train, X_test, y_train, y_test, feature_names)\n",
        "\n",
        "# Evaluate Random Forest model\n",
        "(rf_train_mae, rf_train_mse, rf_train_rmse, rf_train_r2, rf_test_mae, rf_test_mse, rf_test_rmse, rf_test_r2,\n",
        " rf_train_results, rf_test_results) = evaluate_model(rf_model, X_train, X_test, y_train, y_test, feature_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69dlTssXQmyh"
      },
      "outputs": [],
      "source": [
        "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# def evaluate_model(model, X_train, X_test, y_train, y_test, feature_names):\n",
        "#     # Fit the model\n",
        "#     model.fit(X_train, y_train)\n",
        "\n",
        "#     # Predictions\n",
        "#     y_train_pred = model.predict(X_train)\n",
        "#     y_test_pred = model.predict(X_test)\n",
        "\n",
        "#     # Training metrics\n",
        "#     train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "#     train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "#     train_rmse = np.sqrt(train_mse)\n",
        "#     train_r2 = r2_score(y_train, y_train_pred)\n",
        "\n",
        "#     # Testing metrics\n",
        "#     test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "#     test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "#     test_rmse = np.sqrt(test_mse)\n",
        "#     test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "#     # Collect results\n",
        "#     train_results = pd.DataFrame({\n",
        "#         'Actual': y_train,\n",
        "#         'Predicted': y_train_pred,\n",
        "#         'Feature Importance': feature_names\n",
        "#     })\n",
        "\n",
        "#     test_results = pd.DataFrame({\n",
        "#         'Actual': y_test,\n",
        "#         'Predicted': y_test_pred,\n",
        "#         'Feature Importance': feature_names\n",
        "#     })\n",
        "\n",
        "#     return (train_mae, train_mse, train_rmse, train_r2, test_mae, test_mse, test_rmse, test_r2,\n",
        "#             train_results, test_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "O9kxowoZP4cd",
        "outputId": "11682253-5b4d-40c0-d648-8bf4140bf045"
      },
      "outputs": [],
      "source": [
        "# # Define models to evaluate\n",
        "# models = {\n",
        "#     'Linear Regression': LinearRegression(),\n",
        "#     'Ridge Regression': Ridge(),\n",
        "#     'Lasso Regression': Lasso(),\n",
        "#     'Decision Tree': DecisionTreeRegressor(),\n",
        "#     'Random Forest': RandomForestRegressor(),\n",
        "#     'Gradient Boosting': GradientBoostingRegressor()\n",
        "# }\n",
        "\n",
        "# # Initialize results storage\n",
        "# model_metrics = {}\n",
        "# r2_scores = []\n",
        "\n",
        "# # Feature names\n",
        "# feature_names = X_train.columns.tolist()\n",
        "\n",
        "# # Evaluate each model\n",
        "# for name, model in models.items():\n",
        "#     (train_mae, train_mse, train_rmse, train_r2, test_mae, test_mse, test_rmse, test_r2,\n",
        "#      train_results, test_results) = evaluate_model(model, X_train, X_test, y_train, y_test, feature_names)\n",
        "\n",
        "#     # Store metrics\n",
        "#     model_metrics[name] = {\n",
        "#         'Train MAE': train_mae,\n",
        "#         'Train MSE': train_mse,\n",
        "#         'Train RMSE': train_rmse,\n",
        "#         'Train R2': train_r2,\n",
        "#         'Test MAE': test_mae,\n",
        "#         'Test MSE': test_mse,\n",
        "#         'Test RMSE': test_rmse,\n",
        "#         'Test R2': test_r2\n",
        "#     }\n",
        "\n",
        "#     # Collect R2 scores for plotting\n",
        "#     r2_scores.append((name, 'Train', train_r2))\n",
        "#     r2_scores.append((name, 'Test', test_r2))\n",
        "\n",
        "# # Print the results\n",
        "# for name, metrics in model_metrics.items():\n",
        "#     print(f\"{name} Metrics:\")\n",
        "#     print(f\"  Train MAE: {metrics['Train MAE']}, MSE: {metrics['Train MSE']}, RMSE: {metrics['Train RMSE']}, R2: {metrics['Train R2']}\")\n",
        "#     print(f\"  Test MAE: {metrics['Test MAE']}, MSE: {metrics['Test MSE']}, RMSE: {metrics['Test RMSE']}, R2: {metrics['Test R2']}\")\n",
        "#     print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1Vjfr35P8hm"
      },
      "outputs": [],
      "source": [
        "# # Plot comparison of R2 scores\n",
        "# labels = [f\"{name} {kind}\" for name, kind, _ in r2_scores]\n",
        "# r2_values = [score for _, _, score in r2_scores]\n",
        "\n",
        "# plt.figure(figsize=(14, 8))\n",
        "# plt.bar(labels, r2_values, color=['blue', 'lightblue', 'green', 'lightgreen', 'red', 'pink', 'orange', 'yellow', 'purple', 'violet', 'brown', 'lightbrown'])\n",
        "# plt.title('Comparison of R-squared Scores')\n",
        "# plt.ylim(min(r2_values) - 0.1, max(r2_values) + 0.1)\n",
        "# plt.ylabel('R-squared Score')\n",
        "# plt.xticks(rotation=45, ha='right')\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPE9WDPMP8dN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZ81zy8K6NcM",
        "outputId": "70eb40bc-a29c-49d7-ddaa-2ea887897ace"
      },
      "outputs": [],
      "source": [
        "# Print metrics for both models\n",
        "print(\"Linear Regression Metrics:\")\n",
        "print(f\"  Train MAE: {lr_train_mae}, MSE: {lr_train_mse}, RMSE: {lr_train_rmse}, R2: {lr_train_r2}\")\n",
        "print(f\"  Test MAE: {lr_test_mae}, MSE: {lr_test_mse}, RMSE: {lr_test_rmse}, R2: {lr_test_r2}\")\n",
        "\n",
        "print(\"\\nRandom Forest Metrics:\")\n",
        "print(f\"  Train MAE: {rf_train_mae}, MSE: {rf_train_mse}, RMSE: {rf_train_rmse}, R2: {rf_train_r2}\")\n",
        "print(f\"  Test MAE: {rf_test_mae}, MSE: {rf_test_mse}, RMSE: {rf_test_rmse}, R2: {rf_test_r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kw3pWZk06QaP",
        "outputId": "4aeb1bda-5b2c-4757-f6bb-98675ef7c8d7"
      },
      "outputs": [],
      "source": [
        "# Print a sample of the train and test results\n",
        "print(\"\\nSample of Linear Regression Train Results:\")\n",
        "print(lr_train_results.head())\n",
        "\n",
        "print(\"\\nSample of Linear Regression Test Results:\")\n",
        "print(lr_test_results.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgLu4hJF80kZ",
        "outputId": "966b2425-ec00-4868-d729-3ac824f479c9"
      },
      "outputs": [],
      "source": [
        "with pd.option_context('display.max_columns', None):\n",
        "  print(rf_train_results.head(25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        },
        "id": "DPOsQU587bHV",
        "outputId": "ca361894-378a-4203-9de3-a1edca079fd3"
      },
      "outputs": [],
      "source": [
        "print(\"\\nSample of Random Forest Train Results:\")\n",
        "rf_train_results.head(20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        },
        "id": "xC6Dj30w7gt8",
        "outputId": "069a43ea-8de3-4cf9-d94a-bd19004befc3"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"\\nSample of Random Forest Test Results:\")\n",
        "rf_test_results.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "pR6ZS8aJaM0y",
        "outputId": "e465ed5e-a889-427c-8619-56845d52d963"
      },
      "outputs": [],
      "source": [
        "# Plot comparison of R2 scores\n",
        "labels = ['Linear Regression Train', 'Linear Regression Test', 'Random Forest Train', 'Random Forest Test']\n",
        "r2_scores = [lr_train_r2, lr_test_r2, rf_train_r2, rf_test_r2]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(labels, r2_scores, color=['blue', 'lightblue', 'green', 'lightgreen'])\n",
        "plt.title('Comparison of R-squared Scores')\n",
        "plt.ylim(min(r2_scores) - 0.1, max(r2_scores) + 0.1)\n",
        "plt.ylabel('R-squared Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqrpD-JNRaOx",
        "outputId": "bef45773-68ba-47b6-fa69-bd39b59f708e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you have the metrics already calculated and stored in variables\n",
        "\n",
        "# Create a dictionary to hold the metrics\n",
        "metrics_data = {\n",
        "    \"Model\": [\"Linear Regression\", \"Random Forest\"],\n",
        "    \"Train MAE\": [lr_train_mae, rf_train_mae],\n",
        "    \"Train MSE\": [lr_train_mse, rf_train_mse],\n",
        "    \"Train RMSE\": [lr_train_rmse, rf_train_rmse],\n",
        "    \"Train R2\": [lr_train_r2, rf_train_r2],\n",
        "    \"Test MAE\": [lr_test_mae, rf_test_mae],\n",
        "    \"Test MSE\": [lr_test_mse, rf_test_mse],\n",
        "    \"Test RMSE\": [lr_test_rmse, rf_test_rmse],\n",
        "    \"Test R2\": [lr_test_r2, rf_test_r2]\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_data)\n",
        "\n",
        "# Save to CSV\n",
        "metrics_df.to_csv('baseline_model_metrics.csv', index=False)\n",
        "\n",
        "print(\"Metrics saved to model_metrics.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LUybWEB4TrW"
      },
      "source": [
        "###DEPLOYMENT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sCvjyVO4VkC",
        "outputId": "0f38309d-2840-4f62-bce4-4e028b46f1d6"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model to a file\n",
        "model_filename = 'rf_bestest_model.pkl'\n",
        "joblib.dump(best_model, model_filename)\n",
        "print(f\"\\nModel saved to {model_filename} successfully.\")\n",
        "# joblib.dump(label_encoders, 'label_encoders.pkl')\n",
        "# joblib.dump(scaler, 'scaler.pkl')\n",
        "\n",
        "# print(\"Model and preprocessing objects have been saved.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TiN8CB-HKe-"
      },
      "source": [
        "###Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtSlxixUHKBR",
        "outputId": "d9bf819a-f091-429b-e255-d8949103ee9d"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Define the deep learning model\n",
        "def build_model():\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1)  # Output layer for regression\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "# Build the model\n",
        "model = build_model()\n",
        "\n",
        "# Define early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, validation_split=0.2, batch_size=32, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model on the training set\n",
        "train_predictions = model.predict(X_train).flatten()\n",
        "train_mae = mean_absolute_error(y_train, train_predictions)\n",
        "train_mse = mean_squared_error(y_train, train_predictions)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "train_r2 = r2_score(y_train, train_predictions)\n",
        "\n",
        "print(f\"Train Set Evaluation for Deep Learning Model:\")\n",
        "print(f\"  MAE: {train_mae}\")\n",
        "print(f\"  MSE: {train_mse}\")\n",
        "print(f\"  RMSE: {train_rmse}\")\n",
        "print(f\"  R2: {train_r2}\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_predictions = model.predict(X_test).flatten()\n",
        "test_mae = mean_absolute_error(y_test, test_predictions)\n",
        "test_mse = mean_squared_error(y_test, test_predictions)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "test_r2 = r2_score(y_test, test_predictions)\n",
        "\n",
        "print(f\"\\nTest Set Evaluation for Deep Learning Model:\")\n",
        "print(f\"  MAE: {test_mae}\")\n",
        "print(f\"  MSE: {test_mse}\")\n",
        "print(f\"  RMSE: {test_rmse}\")\n",
        "print(f\"  R2: {test_r2}\")\n",
        "\n",
        "# Save the model\n",
        "model.save('deep_learning_best_model.h5')\n",
        "print(\"\\nModel saved successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBFjcvaLSAqQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the deep learning model\n",
        "def build_model():\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1)  # Output layer for regression\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "# Build the model\n",
        "model = build_model()\n",
        "\n",
        "# Define early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Lists to store R2 scores\n",
        "train_r2_scores = []\n",
        "val_r2_scores = []\n",
        "\n",
        "# Train the model and calculate R2 scores after each epoch\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "validation_split = 0.2\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    history = model.fit(X_train, y_train, epochs=1, validation_split=validation_split, batch_size=batch_size, callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "    # Calculate R2 score for the training set\n",
        "    train_predictions = model.predict(X_train).flatten()\n",
        "    train_r2 = r2_score(y_train, train_predictions)\n",
        "    train_r2_scores.append(train_r2)\n",
        "\n",
        "    # Calculate R2 score for the validation set\n",
        "    val_indices = int((1 - validation_split) * len(X_train))\n",
        "    X_val = X_train[val_indices:]\n",
        "    y_val = y_train[val_indices:]\n",
        "    val_predictions = model.predict(X_val).flatten()\n",
        "    val_r2 = r2_score(y_val, val_predictions)\n",
        "    val_r2_scores.append(val_r2)\n",
        "\n",
        "    # Early stopping check\n",
        "    if early_stopping.stopped_epoch > 0:\n",
        "        break\n",
        "\n",
        "# Evaluate the model on the training set\n",
        "train_predictions = model.predict(X_train).flatten()\n",
        "train_mae = mean_absolute_error(y_train, train_predictions)\n",
        "train_mse = mean_squared_error(y_train, train_predictions)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "train_r2 = r2_score(y_train, train_predictions)\n",
        "\n",
        "print(f\"Train Set Evaluation for Deep Learning Model:\")\n",
        "print(f\"  MAE: {train_mae}\")\n",
        "print(f\"  MSE: {train_mse}\")\n",
        "print(f\"  RMSE: {train_rmse}\")\n",
        "print(f\"  R2: {train_r2}\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_predictions = model.predict(X_test).flatten()\n",
        "test_mae = mean_absolute_error(y_test, test_predictions)\n",
        "test_mse = mean_squared_error(y_test, test_predictions)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "test_r2 = r2_score(y_test, test_predictions)\n",
        "\n",
        "print(f\"\\nTest Set Evaluation for Deep Learning Model:\")\n",
        "print(f\"  MAE: {test_mae}\")\n",
        "print(f\"  MSE: {test_mse}\")\n",
        "print(f\"  RMSE: {test_rmse}\")\n",
        "print(f\"  R2: {test_r2}\")\n",
        "\n",
        "# Save the model\n",
        "model.save('deep_learning_best_model.h5')\n",
        "print(\"\\nModel saved successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGQF6hSbSHdv"
      },
      "outputs": [],
      "source": [
        "# Plot the training and validation loss and R2 scores\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs_range = range(1, len(loss_values) + 1)\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Plot for Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, loss_values, 'bo-', label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss_values, 'ro-', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot for R2 Score\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, train_r2_scores, 'bo-', label='Training R2')\n",
        "plt.plot(epochs_range, val_r2_scores, 'ro-', label='Validation R2')\n",
        "plt.title('Training and Validation R2 Score')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('R2 Score')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "x6XsHv84Qocj",
        "outputId": "52395aee-9771-4eca-d06a-c59237a4b09d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assume history is the object returned by the model.fit() method\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "# Plotting the training and validation loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, loss_values, 'bo-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss_values, 'ro-', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ79ogWgjoQf"
      },
      "source": [
        "###Deployemnt trial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "eS6UquXNobgP",
        "outputId": "230efa5f-4220-4356-a26f-6ba8e47c611e"
      },
      "outputs": [],
      "source": [
        "# Save the LabelEncoders using joblib\n",
        "for feature, encoder in label_encoders.items():\n",
        "    joblib.dump(encoder, f'{feature}_label_encoder.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "GvqTZL1Hjq7n",
        "outputId": "950a7f5c-835f-45c0-8e5e-77e3defecfe2"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "# Save the preprocessing steps and the model\n",
        "# Save the LabelEncoders using joblib\n",
        "for feature, encoder in label_encoders.items():\n",
        "    joblib.dump(encoder, f'{feature}_label_encoder.pkl')\n",
        "joblib.dump(scaler, 'minmax_scaler.pkl')\n",
        "joblib.dump(model, 'random_forest_model.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvaGmI7MkckX",
        "outputId": "291f468b-daaa-4048-b463-9a52f1f6c00e"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "# Load the preprocessing steps and the model\n",
        "label_encoder = joblib.load('label_encoders.pkl')\n",
        "minmax_scaler = joblib.load('scaler.pkl')\n",
        "model = joblib.load('rf_bestest_model.pkl')\n",
        "\n",
        "selected_features = ['RECORD_TYPE', 'STATE', 'GROUP_SIZE', 'HOMEOWNER', 'CAR_AGE', 'CAR_VALUE', 'RISK_FACTOR', 'MARRIED_COUPLE', 'AGE_OLDEST', 'C_PREVIOUS', 'DURATION_PREVIOUS', 'A','B', 'C', 'E', 'G']\n",
        "categorical_columns = ['STATE', 'CAR_VALUE']\n",
        "numerical_columns = ['CAR_AGE', 'AGE_OLDEST']\n",
        "\n",
        "def preprocess_input(data):\n",
        "    # Convert input data to DataFrame\n",
        "    df = pd.DataFrame(data, index=[0])\n",
        "\n",
        "    # Apply the same preprocessing as training data\n",
        "    for col in categorical_columns:\n",
        "        if col in label_encoder:\n",
        "            df[col] = label_encoder[col].transform(df[col].astype(str))\n",
        "\n",
        "    df[numerical_columns] = minmax_scaler.transform(df[numerical_columns])\n",
        "\n",
        "    # Select the same features as training data\n",
        "    df_selected = df[selected_features]\n",
        "\n",
        "    return df_selected\n",
        "\n",
        "def predict(data):\n",
        "    preprocessed_data = preprocess_input(data)\n",
        "    prediction = model.predict(preprocessed_data)\n",
        "    rounded_prediction = round(prediction[0], 2)  # Round off to 2 decimal places\n",
        "    return rounded_prediction\n",
        "\n",
        "# Example usage\n",
        "input_data = {\n",
        "    'RECORD_TYPE': 1,\n",
        "    'STATE': 'NY',\n",
        "    'GROUP_SIZE': 2,\n",
        "    'HOMEOWNER': 1,\n",
        "    'CAR_AGE': 5,\n",
        "    'CAR_VALUE': 'b',\n",
        "    'RISK_FACTOR': 3,\n",
        "    'MARRIED_COUPLE': 0,\n",
        "    'AGE_OLDEST': 45,\n",
        "    'C_PREVIOUS': 1,\n",
        "    'DURATION_PREVIOUS': 2.5,\n",
        "    'A': 0,\n",
        "    'B': 1,\n",
        "    'C': 1,\n",
        "    'E': 0,\n",
        "    'G': 1\n",
        "}\n",
        "print(predict(input_data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMoJe2bZkpkV"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "input_data = {\n",
        "    'RECORD_TYPE': 1,\n",
        "    'GROUP_SIZE': 2,\n",
        "    'HOMEOWNER': 1,\n",
        "    'CAR_AGE': 5,\n",
        "    'RISK_FACTOR': 3,\n",
        "    'MARRIED_COUPLE': 0,\n",
        "    'AGE_OLDEST': 45,\n",
        "    'C_PREVIOUS': 1\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "MloxIas-iXrb",
        "outputId": "d13df3ba-73de-4b40-a33f-0aad69bf4554"
      },
      "outputs": [],
      "source": [
        "# Create a boolean mask for the specified columns only\n",
        "mask = pd.Series([True] * len(df))\n",
        "for key, value in input_data.items():\n",
        "    mask &= (df[key] == value)\n",
        "\n",
        "# Extract rows that match the input data\n",
        "matching_rows = df[mask]\n",
        "\n",
        "matching_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oiP1hpel0Wb",
        "outputId": "4779e93d-0b23-4335-bc1c-03bc1585fdff"
      },
      "outputs": [],
      "source": [
        "df['CAR_VALUE'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltGxJsloloX6",
        "outputId": "b4ddebd6-1e9d-4c76-9eac-0eb90a63559f"
      },
      "outputs": [],
      "source": [
        "matching_rows['AGE_OLDEST']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onOqdVCZloAe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lI_7bm8QkghD",
        "outputId": "56c99d94-e275-4c37-e4f6-336457702d20"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load the preprocessing steps and the model\n",
        "label_encoder = joblib.load('label_encoders.pkl')\n",
        "minmax_scaler = joblib.load('scaler.pkl')\n",
        "model = joblib.load('rf_bestest_model.pkl')\n",
        "\n",
        "selected_features = ['RECORD_TYPE', 'STATE', 'GROUP_SIZE', 'HOMEOWNER', 'CAR_AGE', 'CAR_VALUE', 'RISK_FACTOR', 'MARRIED_COUPLE', 'AGE_OLDEST', 'C_PREVIOUS', 'DURATION_PREVIOUS', 'A','B', 'C', 'E', 'G']\n",
        "categorical_columns = ['STATE', 'CAR_VALUE']\n",
        "numerical_columns = ['CAR_AGE', 'AGE_OLDEST']\n",
        "\n",
        "def preprocess_input(data):\n",
        "    # Convert input data to DataFrame\n",
        "    df = pd.DataFrame(data, index=[0])\n",
        "\n",
        "    # Apply the same preprocessing as training data\n",
        "    for col in categorical_columns:\n",
        "        df[col] = label_encoder.transform(df[col])\n",
        "\n",
        "    df[numerical_columns] = minmax_scaler.transform(df[numerical_columns])\n",
        "\n",
        "    # Select the same features as training data\n",
        "    df_selected = df[selected_features]\n",
        "\n",
        "    return df_selected\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    data = request.get_json()\n",
        "    preprocessed_data = preprocess_input(data)\n",
        "    prediction = model.predict(preprocessed_data)\n",
        "    return jsonify({'prediction': prediction.tolist()})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "whIVGoWD5GxK",
        "ZfjYV4FwKklp",
        "jAertoIyv877",
        "JQ0xrIpyEsfe",
        "9gvNvUPJBmGa",
        "2GAWG0OgHUUk",
        "4blFKeK-44E9"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
